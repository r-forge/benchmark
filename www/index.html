
<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en   ">

  <head>
  	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Benchmark Experiments</title>
	<link rel="stylesheet" type="text/css" href="mjaepkg.css" />
  </head>

<body>
  <h1>Benchmark Experiments</h1>
  <div id="h1sub">R package <tt>benchmark</tt></div>

  <p>
    In statistical learning benchmarking is the methodology of
    comparing learners or algorithms with respect to a certain
    performance measure. The benchmarking process abstractly consists
    of three levels: Setup, Execution and Analysis. (1) The Setup
    defines the design of a benchmark experiment; data set, candidate
    algorithms, performance measures and a suitable resampling
    strategy are declared. (2) In the Execution level the defined
    setup is executed. Here, computational aspects play a major role;
    an important example is the parallel computation of the experiment
    on different computers. (3) In the Analysis level the computed raw
    performance measures are analyzed using exploratory and
    inferential methods. This package is mainly concerned with the
    Analysis level; in what the derivation of a statistically correct
    order of the candidate algorithms is a major objective.
  </p>

  <p class="header">
    <a href="http://www.statistik.lmu.de/~eugster/publications/thesis-2011-phd.pdf#page=41"><img src="beplot.png" /></a>
    <a href="http://www.statistik.lmu.de/~eugster/publications/thesis-2011-phd.pdf#page=82"><img src="bsgraph.png" /></a>
    <a href="http://www.statistik.lmu.de/~eugster/publications/thesis-2011-phd.pdf#page=89"><img src="atypes.png" /></a>
  </p>


  <h2>Usage</h2>

  <p>
    The <b>stable version</b> of <tt>benchmark</tt> is available
    on <a href="http://cran.r-project.org/package=benchmark">CRAN</a>;
    issue the following from within R to install and load it:
    <blockquote>
      <pre class="code">
R> install.packages("benchmark")
R> library("benchmark")</pre>
    </blockquote>
  </p>


  <h2>Demos</h2>

  <p>
    <b>benchplot:</b> Exploratory and inferential analysis of the
    monks3 benchmark experiment.
    <blockquote class="code"><pre>
R> demo("benchplot", package = "benchmark")</pre></blockquote>
  </p>
  <p>
    <b>lsbenchplot-uci621:</b> Exploratory and inferential analysis of
    the UCI domain benchmark experiment.
    <blockquote>
    The analysis of six common learning algorithms on
    well-known <a href="http://archive.ics.uci.edu/ml/">UCI</a> data
    sets.

    <pre class="code">
R> demo("lsbenchplot-uci621", package = "benchmark")</pre></blockquote>
  </p>
  <p>
    <b>lsbenchplot-uci621-atypes:</b> Archetypal analysis of the UCI
    domain benchmark experiment.
     <blockquote>
     In general, comparing algorithms often means comparing with a
     "best" or "worst" algorithm, i.e., comparing with an extreme
     algorithm (the benchmark). However, in case of of more than one
     performance measure or more than one data set no uniquely defined
     extreme values are
     available---<a href="http://archetypes.r-forge.r-project.org/">archetypal
     analysis</a> can be used to compute data-driven benchmark algorithms.

     <pre class="code">
R> demo("lsbenchplot-uci621-atypes", package = "benchmark")</pre>
     </blockquote>
  </p>
  <p>
    <b>lsbenchplot-gh:</b> Exploratory and inferential analysis of the
    Grasshopper domain benchmark experiment.
    <blockquote>
     <pre class="code">
R> demo("lsbenchplot-gh", package = "benchmark")</pre>
     </blockquote>
  </p>


  <h2>Development</h2>

  <p>
    The <b>development version</b> is available on
    <a href="https://r-forge.r-project.org/projects/benchmark/">R-Forge</a>.
  </p>

  <p class="footer">
    Created by <a href="http://www.statistik.lmu.de/~eugster"
    style="color: #C0C0C0">Manuel J. A. Eugster</a>, 2011.
  </p>

</body>
</html>
